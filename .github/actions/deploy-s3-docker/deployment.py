import os
import boto3
# boto3 is a package provided by AWS as SDK, which gives us methods for uploading files to S3
# the .upload_file is the method for uploading files. See below.
import mimetypes
from botocore.config import Config


def run():
    # for every input in the action.yml, github generates and env variable
    # prefixed with INPUT_
    # this is analagous to the const variable definitions in the main.js javascript custom action
    # these bolded are Env vars automatically generated by github actions based upon
    # the boto3 dependency that has been added.
    # even Env vars added to workflow file deploy.yml will also get these same types of INPUT_ env vars in python 
    # from github
    bucket = os.environ['INPUT_MY-S3-BUCKET']
    bucket_region = os.environ['INPUT_BUCKET-REGION']
    dist_folder = os.environ['INPUT_DIST-FOLDER']

    configuration = Config(region_name=bucket_region)

    s3_client = boto3.client('s3', config=configuration)
    # this is where the AWS access id and secret will be used by the AWS SKK boto3

    for root, subdirs, files in os.walk(dist_folder):
        for file in files:
            # the upload_file method is from the boto3 AWS python SDK
            s3_client.upload_file(
                os.path.join(root, file),
                bucket,
                os.path.join(root, file).replace(dist_folder + '/', ''),
                ExtraArgs={"ContentType": mimetypes.guess_type(file)[0]}
            )

    website_url = f'http://{bucket}.s3-website-{bucket_region}.amazonaws.com'
    # The below code sets the 'my-website-url' output (the old ::set-output syntax isn't supported anymore - that's the only thing that changed though)
    with open(os.environ['GITHUB_OUTPUT'], 'a') as gh_output:
        print(f'my-website-url={website_url}', file=gh_output)
        # this is not a print to the console but sets the output of this action.yml
        # this is very similar to the core.setOutput in the main.js javascript code.


if __name__ == '__main__':
    run()